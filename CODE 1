import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error
import xgboost as xgb

# 1. Load and Preprocess Data
df = pd.read_csv("/content/Bishub_sir_Datasets 1.csv")
df.fillna(df.mean(), inplace=True)  # Handle missing values
X = df[["WFR", "V", "Time"]]
y = df[["NOx", "CO", "Fe2O3"]]
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# 2. Hyperparameter Tuning and Cross-Validation
# Define the parameter grid for tuning
param_grid = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 0.9, 1.0],
    'colsample_bytree': [0.8, 0.9, 1.0],
}

# Create an XGBoost regressor
xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=64)

# Perform GridSearchCV for hyperparameter tuning
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_mean_squared_error', cv=5, verbose=1)
grid_search.fit(X_train, y_train)

# Get the best model from GridSearchCV
best_xgb_model = grid_search.best_estimator_

# 3. Train the Best Model
# The best model is already trained during GridSearchCV, but we can refit on the whole training data if needed
# best_xgb_model.fit(X_train, y_train)

# 4. Evaluate the Model
y_pred = best_xgb_model.predict(X_test)
r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
print(f"XGBoost R-squared: {r2}")
print(f"XGBoost MSE: {mse}")

# 5. Prediction Function
# Pass the trained model as an argument to the function
def predict_for_WFR(WFR, V, Time, scaler, trained_model):
    input_data = pd.DataFrame([[WFR, V, Time]],
                              columns=["WFR", "V", "Time"])
    input_data_scaled = scaler.transform(input_data)
    # Use the passed trained_model for prediction
    predicted_outputs = trained_model.predict(input_data_scaled)[0]
    output_names = ["NOx", "CO", "Fe2O3"]
    for name, value in zip(output_names, predicted_outputs):
        print(f"{name}: {value}")
    return predicted_outputs

# 6. Example Prediction
WFR = float(input("Enter the Value: "))
V = 20
Time = 1.5
# Pass the best_xgb_model to the prediction function
predictions = predict_for_WFR(WFR=WFR, V=V, Time=Time, scaler=scaler, trained_model=best_xgb_model)
